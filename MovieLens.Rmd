---
title: "Movie Rating Predictions"
author: "Jean-Marie Roy"
date: "2026-01-28"
output:
  pdf_document:
    toc: false
    toc_depth: 2
    extra_dependencies: ["float"]
    latex_engine: xelatex
  html_document:
    df_print: paged
header-includes:
  - \usepackage{xcolor}
  - \usepackage[table]{xcolor}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = "H", out.extra = "")
```

```{r, echo=FALSE}
# To increase the speed of the rendering, we only run the "MovieLens" code separately,
# and use the variables stored in the global environment.
# This also allows to reduce the size of the Rmd file by moving as much code as possible to the R file.
# To be able to access the variables, the markdown code should be run in the console :
#
# rmarkdown::render("MovieLens.Rmd")
#
# The other option is to include the script in this file by removing the comment of the line below :
#
# source("MovieLens.R")
#
# Note that the image below is decorative onle and will be downloaded from github
# when running the MovieLens script.
#
```

\begin{center}
\vspace*{\fill}

\includegraphics[width=0.2\textwidth]{movielens-cover.png}

\vspace*{\fill}
\end{center}

\newpage

\tableofcontents

\newpage

# 1. Introduction

## 1.1 Objective

The purpose of this document is to explain how to create a movie recommendation system using the MovieLens dataset.
During the PH125.8x: Data Science: Machine Learning course, the dataset used was from the the dslabs package. For this exercise, we will use a 10M rows dataset available here :

>https://grouplens.org/datasets/movielens/10m/

The history and context of this dataset are available here :

\begin{center}
\colorbox{gray!10}{
  \begin{minipage}{0.90\textwidth}
    F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872
  \end{minipage}
}
\end{center}

First we will setup the environment and download and generate the dataset, then we will analyse the data, and finally we will train a machine learning algorithm using the inputs in the first subset (edx) to predict the movie ratings in the validation set (final_holdout_test).

The goal of this exercise is to be able to predict the movie ratings in the test set with a root mean square error (RMSE) lower than **0.86490**.

This task is inspired by the Netflix challenge, which aimed to predict ratings without utilizing any user data (such as age or gender) due to privacy concerns. Ultimately, the goal is to predict which films a user would enjoy based on their previous ratings.

## 1.2 Data preparation

This section explains how the data is imported and prepared for further analysis. A portion of the process is based on the code provided in the course, specifically within the “01 Setup.R” script.

The code processes the MovieLens 10M dataset to create training (edx) and testing (final_holdout_test) datasets suitable for analysis.

It begins by checking for necessary libraries, downloading the dataset, and extracting the ratings and movies files if they aren't already present. It reads and cleans the data, ensuring that columns are correctly formatted.

The main dataset is created by merging ratings with movie details, and then a random subset is taken as a test set (10% of the data). To maintain consistency, only those users and movies present in the training set are included in the final test set. Any excluded rows are then added back to the training set. Finally, the code cleans up by removing unnecessary variables.

\newpage

# 2 Exploratory Data Analysis

## 2.1 Structure

This section provides an overview of the datasets used in our analysis. We have two datasets: one for training our prediction algorithm and another for testing its effectiveness.

The training dataset, edx, shares the same structure as the final_holdout_test dataset, which is used for testing.

The edx dataset contains approximately 9 million ratings for various movies and consists of six variables :

| Variable         | Description                                    |
|------------------|------------------------------------------------|
| `userId`         | User ID (anonymised)                       |
| `movieId`        | Unique movie ID                            |
| `rating`         | Rating from 0 to 5 including half numbers (1.5, 2.5...) |
| `timestamp`      | Date and time the rating was created. It is stored as a number of seconds since the 1st of January 1970          |
| `title`          | Title of the movie with the year it was released, in the form "name (year)"          |
| `genres`         | Genre of the movie (action, drama...)          |

From the dataset, we can determine the total counts of movies, users, and ratings :

```{r, echo=FALSE}
data_summary <- data.frame(Dataset = c("edx", "final_holdout_test"),
                           Type = c("Train", "Test"),
                           Movies = c(comma(n_distinct(edx$movieId)), comma(n_distinct(final_holdout_test$movieId))),
                           Users = c(comma(n_distinct(edx$userId)), comma(n_distinct(final_holdout_test$userId))),
                           Ratings = c(comma(nrow(edx)), comma(nrow(final_holdout_test))))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

The analysis reveals that for the edx dataset, approximately 10,000 movies were rated by 70,000 users, resulting in a total of 9,000,000 ratings.

\newpage

## 2.2 Data Transformation

The first few entries of the edx dataset suggest potential transformations for enhanced analysis :

```{r, echo=FALSE}
data_summary <- head(edx %>% select(userId, movieId,
                                    rating, timestamp,
                                    title, genres))
# Replace '|' with ';' in the genres column
data_summary$genres <- gsub("\\|", ";", data_summary$genres)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

The timestamp variable can be decomposed into various components, including the day of the week, day, month, year, and hour (minutes and seconds are likely unnecessary for our analysis).

Additionally, the title variable contains the release year formatted as "title (year)." We can extract both the title without the year and the year of release.

While we can also separate the genres, we are not permitted to add rows to the dataset, only columns, so this transformation is not feasible.


The table below displays the modified edx dataset, which retains the genres column but omits it from this view due to space constraints :

```{r, echo=FALSE}
data_summary <- head(edx_movies %>% select(userId, movieId,
                                           rating, t_day_of_week,
                                           t_day, t_month,
                                           t_year, t_hour,
                                           title, year))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

The statistics for the modified table, focusing on the numerical variables (excluding userId and movieId, which are identifiers), are presented below :

```{r, echo=FALSE}
data_summary <- summary(edx_movies %>% select(rating, t_day_of_week, t_day, t_month, t_year, t_hour, year))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

This allows us to focus on the other relevant attributes for analysis while keeping the genres information in the dataset.

\newpage

## 2.3 Data Analysis

### 2.3.1 Variables

List of variables and their distinct value counts :

```{r, echo=FALSE}
# List of variables and number of distinct values
data_summary <- edx_movies %>%
  select(userId, movieId, t_day_of_week, t_day,
         t_month, t_year, t_hour, title, year, genres) %>%
  summarise(across(everything(), ~ n_distinct(.))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Distinct_Count") %>%
  arrange(desc(Distinct_Count))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

There are approximately 70,000 users who have rated 10,000 movies. Notably, the number of movies slightly exceeds the number of titles, likely because some films share the same title (possibly due to remakes released years later). While there are 20 genres (see section 2.3.6 for more details), nearly 800 combinations of these genres exist. The movies were released over a span of 94 years, and the timestamps for the ratings encompass all hours of the day, every day of the week, and every month of the year.

### 2.3.2 Correlations

The table below presents the matrix of correlations among the variables :

```{r, echo=FALSE}
kable(correlation_matrix, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position")) %>%
  row_spec(seq(1, nrow(correlation_matrix), by = 2), background = "#f2f2f2")
```

For better reading of the matrix, all values close to zero (ie between -0.1 and 0.1) have been removed or hidden in the matrix.

As expected, the correlation is 0.98 between movieId and title, indicating a very strong relationship. While most movies have a unique title, some of them like remake share the same title. 

We also discovered that movieId and t_year (and titleId and t_year) have a correlation of approximately 0.5, suggesting that there are movies that are consistently associated with specific timestamp years.

Variance in movieId and year (0.23) suggests that certain movies may tend to receive ratings in certain years but is relatively weak.

Genres correlations are generally low with other variables, e.g., 0.18 with movieId, indicating that genre alone doesn't significantly explain relationships with movie IDs.

t_month has a minor negative correlation with t_year (-0.16) suggesting a slight inverse relationship, possibly indicating that as certain months progress, there might be changes affecting yearly trends.

Rating : the correlations with other variables range slightly around zero, indicating that ratings do not have strong relations with user or movie identifiers or time dimensions, and therefore that user ratings will require deeper analysis.

### 2.3.3 Keys

The goal of our future analysis is to find which groups of variables can serve as identifiers or keys for our dataset.

Research suggests that most Americans can be uniquely identified using just a combination of their zip code, sex, and birth date. In our analysis, we need to explore which combinations of variables can almost pinpoint a user's rating. These combinations should be avoided because, while they may perform well on training data, they are likely to lead to poor predictions on test data.

In our current dataset, the combination of (movieId, userId) serves as a reliable key, as each user rates a specific movie only once. For example, the figure below illustrates the ratings represented on the z-axis, with movieId on the x-axis and userId on the y-axis :

```{r, echo=FALSE, fig.align="center", fig.cap = "Rating per user and movie", fig.height=5}
persp(interp_data$x, interp_data$y, interp_data$z, main = "Ratings", 
      xlab = "Movie ID", ylab = "User ID", zlab = "Rating",
      theta = 30, phi = 30, expand = 0.5, col = "lightblue",shade = 0.5,
      cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)
```

\newpage

The table below shows the uniqueness of combinations : the edx dataset was split into 2 parts (90%-10%), and the figures represent the number of rows in the test_set (total 900,006 rows) not in the train_set :

```{r, echo=FALSE}
kable(unique_rows_2d, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

We can observe that while the couple (userId, movieId) is unique, the couples (userId, genres) and (userId, year) represent a significant amount of observations, not enough to identify a unique observation, but still too high for the exercise.

We can go further and calculate the number of unique rows for a combination of size 3 :

```{r, echo=FALSE}
kable(unique_rows_3d, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

As we can see, the first 6 rows have a significant high number of unique rows. The first 3 rows are based on movieId and userId (with either year or t_year) and therefore are unique.

(userId, year, genres), (userId, t_year, genres) and (userId, t_year, year) have too many rows to be of interest.


For the upcoming analysis, we will only consider the following combinations :  

\begin{table}[ht]
\centering
\begin{tabular}{lll}
    (movieId, t\_year) & (userId, t\_year) & (t\_year, genres) \\
    (movieId, year) & (movieId, genres) & (year, genres) \\
    (t\_year, year) & (movieId, t\_year, year) & (movieId, t\_year, genres) \\
    (t\_year, year, genres) & (movieId, year, genres) &  \\
\end{tabular}
\end{table}

\newpage

### 2.3.4 Movies

The top five movies with the highest number of ratings each received 30,000 ratings, indicating that half of the users rated these films :

```{r, echo=FALSE}
# Top 5 movies with the highest number of ratings.
# We need to reformat the year as character so it is not displayed with a comma (1,994)
data_summary <- top_n(list_movies %>% mutate(year = as.character(year)) %>% select(index, title, year, count), 5, count)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

#### Movie Ratings Visualization

The left figure illustrates that a small number of movies received the majority of ratings, while most received very few.

To better highlight this trend, we can apply a log10 transformation to the y-axis. This transformation reveals that although most movies garnered at least 10 ratings, only half exceeded 100 ratings, as demonstrated in the right figure :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings / Movie", fig.height=2}
plot_grid(
  list_movies %>% sample_n(1000) %>% ggplot(aes(x = index, y = count)) +
    geom_area(color = "darkblue", fill="darkblue", alpha = 0.1) +
    theme_minimal() + theme(text = element_text(size = 9)) +
    labs(x = "MovieId", y = "Number of Ratings"),
  list_movies %>% sample_n(1000) %>% ggplot(aes(x = index, y = count)) +
    geom_area(color = "darkblue", fill="darkblue", alpha = 0.1) +
    theme_minimal() + theme(text = element_text(size = 9)) +
    labs(x = "MovieId", y = "Number of Ratings (log10)") +
    scale_y_log10(),
  ncol = 2)
```

\newpage

#### Movie Release and Ratings Trends

The figure on the left shows that the number of movies released per year increased significantly during the 1980s.

Similarly, the figure on the right demonstrates that the number of ratings received per year for newly released movies also rose during this period. However, it appears that older movies received significantly fewer ratings compared to more recent releases :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of Movies Released per Year and Number of Ratings per Year", fig.height=2}
plot_grid(
  list_movies %>%
    group_by(year) %>%
    summarise(total_movies = n()) %>%
    ggplot(aes(x = year, y = total_movies)) +
    geom_bar(stat = "identity", fill="darkblue", alpha = 0.8) +
    labs(x = "Year Movie Released", y = "Number of Movies") +
    theme_minimal() + theme(text = element_text(size = 9)),
  list_movies %>%
    ggplot(aes(x = year, y = count)) +
    geom_bar(stat = "identity", fill="darkblue", alpha = 0.8) +
    scale_y_continuous(labels = label_number(scale = 1e-3, suffix = "k")) +
    labs(x = "Year Movie Released", y = "Number of Ratings") +
    theme_minimal() + theme(text = element_text(size = 9)),
  ncol = 2)
```

Further investigation reveals that older movies receive slightly fewer ratings (per movie) compared to more recent ones. Additionally, the number of ratings decreases significantly with the age of the movie, which is determined by the difference between the year of the rating and the year of the movie's release :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of Ratings per Movie per year of release and number of ratings per age of movie", fig.height=2}
# Number of Ratings per Movie per year of release,
# and number of ratings per age of movie (difference between the timestamp year and the year of release) :
plot_grid(
  edx_movies %>%
    group_by(year) %>%
    summarize(ratio = n() / n_distinct(movieId)) %>%
    arrange(year) %>%
    ungroup() %>%
    ggplot(aes(x = year, y = ratio)) +
    geom_bar(stat = "identity", fill="darkblue", alpha = 0.8) +
    labs(x = "Year", y = "Nb Ratings per Movie") +
    theme_minimal() + theme(text = element_text(size = 9)),
  edx_movies %>%
    mutate(age = t_year - year) %>%
    group_by(age) %>%
    summarize(count = n()) %>%
    arrange(desc(count)) %>%
    ungroup() %>%
    ggplot(aes(x = age, y = count)) +
    geom_bar(stat = "identity", fill="darkblue", alpha = 0.8) +
    scale_y_continuous(labels = label_number(scale = 1e-3, suffix = "k")) +
    labs(x = "Movie Age", y = "Ratings") +
    theme_minimal() + theme(text = element_text(size = 9)),
  ncol = 2)
```

\newpage

### 2.3.5 Users

As previously mentioned, the edx dataset contains approximately 70,000 users. Below are the top five users with the highest number of ratings :

```{r, echo=FALSE}
data_summary <- top_n(list_users, 5, count)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

A small number of users account for a large proportion of ratings, as shown in the figure on the left, which illustrates that the majority of ratings come from a minority of users.

By applying a log10 transformation to the y-axis, we can see that all users rated at least 10 movies, while only one-third rated more than 100 movies, as depicted in the figure on the right :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings / User", fig.height=2}
plot_grid(
  list_users %>% sample_n(1000) %>% ggplot(aes(x = index, y = count)) +
    geom_area(color = "darkgreen", fill="darkgreen", alpha = 0.1) +
    theme_minimal() + theme(text = element_text(size = 9)) +
    labs(x = "UserId", y = "Number of Ratings"),
  list_users %>% sample_n(1000) %>% ggplot(aes(x = index, y = count)) +
    geom_area(color = "darkgreen", fill="darkgreen", alpha = 0.1) +
    theme_minimal() + theme(text = element_text(size = 9)) +
    labs(x = "UserId", y = "Number of Ratings (log10)") +
    scale_y_log10(),
  ncol = 2)
```

### 2.3.6 Genres

The table below shows the first five observations of the dataset. As we can see, each movie is associated with a genre, which may consist of a combination of different genres :

```{r, echo=FALSE}
# Top 5 observations showing genres :
data_summary <- head(edx_movies %>% select(userId, rating, title, year, genres))
# Replace '|' with ';' in the genres column
data_summary$genres <- gsub("\\|", ";", data_summary$genres)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

From this dataset, we can extract all unique genres, resulting in the following list:

Action, Adventure, Animation, Children, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, IMAX, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western, (no genres listed)

While there are 20 distinct genres, there are 797 combinations of these genres present in the dataset.

\newpage

Next, we will plot the number of ratings per genre (separated):

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings / Genre", fig.width=8, fig.height=4}
list_genres %>%
  arrange(desc(count)) %>%
  mutate(genres = factor(genres, levels = genres)) %>%
  ggplot(aes(x = genres, y = count)) +
  geom_bar(stat = "identity", fill="darkcyan", alpha = 0.8) +
  scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
  labs(x = "Genre", y = "Ratings") +
  theme_minimal() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The bar chart suggests that various genres contribute differently to the total ratings. With genres like Drama and Comedy receiving the most ratings, these may indicate a wider audience appeal and are likely to be favorites among viewers.

Finally, we will plot the number of ratings per genre (combined) along with the cumulative percentage :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings / Genre", fig.height=3}
plot_grid(
  edx_movies %>%
    group_by(genres) %>%
    summarize(
      count = n(),
      average_rating = mean(rating),
      min_rating = min(rating),
      max_rating = max(rating),
      .groups = 'drop') %>%
    arrange(desc(count)) %>%
    mutate(index = row_number()) %>%
    ggplot(aes(x = index, y = count)) +
    geom_bar(stat = "identity", fill="darkcyan", alpha = 0.8) +
    scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
    labs(x = "Genre ID (combination)", y = "Ratings") +
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)),

  edx_movies %>%
    group_by(genres) %>%
    summarize(
      count = n(),
      average_rating = mean(rating),
      min_rating = min(rating),
      max_rating = max(rating),
      .groups = 'drop') %>%
    arrange(desc(count)) %>%
    mutate(index = row_number(),
           percentage = (count / sum(count)) * 100) %>%
    mutate(cumulative_count = cumsum(count),
           total_count = sum(count),
           cumulative_percentage = (cumulative_count / total_count) * 100) %>%
    ggplot(aes(x = index, y = cumulative_percentage)) +
    geom_area(color = "darkcyan", fill="darkcyan", alpha = 0.1) +
    scale_y_continuous(
      labels = label_number(scale = 1, suffix = "%"),  # Scale for percentage labels
      breaks = seq(0, 100, by = 10)) +
    labs(x = "Genre ID (combination)", y = "Cumulative percentage of Ratings") +
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)),

  ncol = 2)
```

The initial steep decline in the histogram indicates that a limited number of genre combinations are common, while the majority of genres are represented infrequently.

The cumulative percentage plot suggests that a small number of genre IDs contribute significantly to the overall dataset : the first 200 genres (out of 797) count for 90% of the ratings.

The following plot shows the number of ratings per movie, per genre and per year :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings per Genre and Year", fig.height=4}
edx_movies %>%
  group_by(year, movieId, genres) %>%
  summarize(
    count_ratings = n(),
    .groups = 'drop') %>%
  separate_rows(genres, sep = "\\|") %>%
  group_by(year, genres) %>%
  summarize(
    count = sum(count_ratings),
    ratings = sum(count_ratings) / n(),
    .groups = 'drop') %>%
  ggplot(aes(x = year, y = ratings, color = genres)) +
  geom_smooth(se = FALSE, method = "loess", size = 1, formula = y ~ x) +
  labs(x = "Year", y = "Number of Ratings per movie") +
  scale_y_continuous(labels = label_number(scale = 1e-3, suffix = "k")) +
  theme_minimal() + theme(text = element_text(size = 8), legend.position = "bottom", legend.key.size = unit(0.1, "cm"))
```

The plot indicated that some genres (Animation, Children, Fantasy, Mystery...) were popular in the 1940s and regained some popularity in the 1990s.

Other genres have seen their number of ratings per movie increase more recently, maybe as the number of movies released increased in the 1980s.

\newpage

The following plot shows the number of ratings per genre over the years :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings per Genre and Year", fig.height=4}
edx_movies %>%
  group_by(year, genres) %>%
  summarize(
    count_ratings = n(),
    .groups = 'drop') %>%
  separate_rows(genres, sep = "\\|") %>%
  group_by(year, genres) %>%
  summarize(
    count = sum(count_ratings),
    .groups = 'drop') %>%
  ggplot(aes(x = year, y = count, color = genres)) +
geom_smooth(se = FALSE, method = "loess", size = 1, formula = y ~ x) +
  labs(x = "Year", y = "Number of Ratings") +
  scale_y_continuous(labels = label_number(scale = 1e-3, suffix = "k")) +
theme_minimal() + theme(text = element_text(size = 8), legend.position = "bottom", legend.key.size = unit(0.1, "cm"))
```

Most genres experience a marked increase in ratings around the 1980s, indicating a proliferation of films, especially in genres like Action, Adventure, and Comedy.

By the late 2000s, genres such as Action, Comedy, and Drama show significantly higher ratings compared to others, indicating their popularity among viewers.

The decrease in ratings in 2010 is likely because users may not have had the time to rate the latest movies.

For the remainder of the analysis, we will use the combined genres.

\newpage

### 2.3.7 Timestamp

We will now study the impact of the timestamp (data and time a rating was given) on the other variables.

The following five plots show the number of ratings per date (timestamp), grouped by movie, user, genres or year of release for the last four ones :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings per date (timestamp)", fig.height=5}
plot_grid(
  edx_movies %>%
    group_by(t_year, t_month) %>%
    summarise(count = n(), .groups = 'drop') %>%
    mutate(year_month = as.Date(paste(t_year, t_month, "01", sep = "-"))) %>%
    ggplot(aes(x = year_month, y = count)) +
    geom_area(color = "black", fill="black", alpha = 0.1) +
    labs(title = "Total",x = "Timestamp", y = "Number of Ratings") +
    scale_y_continuous(labels = label_number(scale = 1e-3, suffix = "k")) +
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)),

  edx_movies %>%
    group_by(t_year, t_month) %>%
    summarise(count = n_distinct(movieId), .groups = 'drop') %>%
    mutate(year_month = as.Date(paste(t_year, t_month, "01", sep = "-"))) %>%
    ggplot(aes(x = year_month, y = count)) +
    geom_area(color = "darkblue", fill="darkblue", alpha = 0.1) +
    labs(title = "Movies",x = "Timestamp", y = "Number of Ratings") +
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)),

  edx_movies %>%
    group_by(t_year, t_month) %>%
    summarise(count = n_distinct(userId), .groups = 'drop') %>%
    mutate(year_month = as.Date(paste(t_year, t_month, "01", sep = "-"))) %>%
    ggplot(aes(x = year_month, y = count)) +
    geom_area(color = "darkgreen", fill="darkgreen", alpha = 0.1) +
    labs(title = "Users",x = "Timestamp", y = "Number of Ratings") +
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)),

  edx_movies %>%
    group_by(t_year, t_month) %>%
    summarise(count = n_distinct(genres), .groups = 'drop') %>%
    mutate(year_month = as.Date(paste(t_year, t_month, "01", sep = "-"))) %>%
    ggplot(aes(x = year_month, y = count)) +
    geom_area(color = "darkcyan", fill="darkcyan", alpha = 0.1) +
    labs(title = "Genres",x = "Timestamp", y = "Number of Ratings") +
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)),

  edx_movies %>%
    group_by(t_year, t_month) %>%
    summarise(count = n_distinct(year), .groups = 'drop') %>%
    mutate(year_month = as.Date(paste(t_year, t_month, "01", sep = "-"))) %>%
    ggplot(aes(x = year_month, y = count)) +
    geom_area(color = "orange", fill="orange", alpha = 0.1) +
    labs(title = "Year of Release",x = "Timestamp", y = "Number of Ratings") +
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)),
  
ncol = 2)
```

The total and user plots, along with the movie, genres, and release year plots, all share a similar shape, indicating a relationship among them.

We observe some variation across all five plots, and unlike the previous plots for release year, there isn’t a sustained period of low ratings.

This suggests that the timestamp may be a more effective variable for predicting ratings than the release year, as it avoids low ratings for movies or users.

\newpage

### 2.3.8 Ratings

Users assigned more full marks than half marks. The figures below illustrate that the distribution of ratings can be approximated as normal when rounded :

```{r, echo=FALSE, fig.align="center", fig.cap = "Number of ratings", fig.height=2}
plot_grid(
  ggplot(edx_movies, aes(x = rating)) +
    geom_histogram(fill="darkred", alpha = 0.8, position="dodge", bins = 30) +
    scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(legend.position = "top", text = element_text(size = 9)) +
    labs(x = "Rating", y = "Count"),
  ggplot(edx_movies, aes(x = floor(rating))) +
    geom_histogram(fill="darkred", alpha = 0.8, position="dodge", bins = 30) +
    scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(legend.position = "top", text = element_text(size = 9)) +
    labs(x = "Rating (Rounded)", y = "Count"),
  ncol = 2)
```

The table below displays the average and standard deviation :

```{r, echo=FALSE}
data_summary <- data.frame(Type = c("Average", "Standard Deviation"),
                           Value = c(mu, sd))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

We will now investigate whether any variable has an impact on the ratings and, consequently, if it can assist in predicting ratings.

\newpage

#### 2.3.8.1 Variables with Low Distinct Values  

We will start by analyzing variables with a low number of distinct values, specifically the timestamp information and the year of release. The aim is to determine whether there are specific times or days when users tend to give higher or lower ratings, or if the year of release influences the ratings :

```{r, echo=FALSE, fig.align="center", fig.cap = "Distribution of ratings per variable", fig.height=3}
plot_grid(
  ggplot(avg_rating_per_day_of_week, aes(x = t_day_of_week)) +
    geom_ribbon(aes(ymin = min_rating, ymax = max_rating), fill = "darkred", alpha = 0.2) +
    geom_line(aes(y = min_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = max_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = avg_rating), color = "darkred", size = 1.2, linetype = "solid") +
    labs(x = "Day of the Week", y = "Rating") +
    scale_y_continuous(limits = c(0, 5)) +
    theme_minimal() + theme(text = element_text(size = 9)),

  ggplot(avg_rating_per_day, aes(x = t_day)) +
    geom_ribbon(aes(ymin = min_rating, ymax = max_rating), fill = "darkred", alpha = 0.2) +
    geom_line(aes(y = min_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = max_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = avg_rating), color = "darkred", size = 1.2, linetype = "solid") +
    labs(x = "Day", y = "Rating") +
    scale_y_continuous(limits = c(0, 5)) +
    theme_minimal() + theme(text = element_text(size = 9)),

  ggplot(avg_rating_per_month, aes(x = t_month)) +
    geom_ribbon(aes(ymin = min_rating, ymax = max_rating), fill = "darkred", alpha = 0.2) +
    geom_line(aes(y = min_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = max_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = avg_rating), color = "darkred", size = 1.2, linetype = "solid") +
    labs(x = "Month", y = "Rating") +
    scale_y_continuous(limits = c(0, 5)) +
    theme_minimal() + theme(text = element_text(size = 9)),

  ggplot(avg_rating_per_t_year, aes(x = t_year)) +
    geom_ribbon(aes(ymin = min_rating, ymax = max_rating), fill = "darkred", alpha = 0.2) +
    geom_line(aes(y = min_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = max_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = avg_rating), color = "darkred", size = 1.2, linetype = "solid") +
    labs(x = "Year (timestamp)", y = "Rating") +
    scale_y_continuous(limits = c(0, 5)) +
    theme_minimal() + theme(text = element_text(size = 9)),
  
  ggplot(avg_rating_per_hour, aes(x = t_hour)) +
    geom_ribbon(aes(ymin = min_rating, ymax = max_rating), fill = "darkred", alpha = 0.2) +
    geom_line(aes(y = min_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = max_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = avg_rating), color = "darkred", size = 1.2, linetype = "solid") +
    labs(x = "Hour", y = "Rating") +
    scale_y_continuous(limits = c(0, 5)) +
    theme_minimal() + theme(text = element_text(size = 9)),
  
  ggplot(avg_rating_per_year, aes(x = year)) +
    geom_ribbon(aes(ymin = min_rating, ymax = max_rating), fill = "darkred", alpha = 0.2) +
    geom_line(aes(y = min_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = max_rating), color = "darkred", linetype = "solid") +
    geom_line(aes(y = avg_rating), color = "darkred", size = 1.2, linetype = "solid") +
    labs(x = "Year (release)", y = "Rating") +
    scale_y_continuous(limits = c(0, 5)) +
    theme_minimal() + theme(text = element_text(size = 9)),
  
  ncol = 3, align = 'hv', rel_heights = c(2, 2, 2))
```

As observed, only the timestamp (year) and year of release exhibit sufficient variation (considering both the mean and minimum values for the timestamp) to be included in the forthcoming analysis.

Note that for both year (timestamp) and year of release, the variation was mainly when there is a low number of ratings, which means it may not be sufficient for predicting the ratings.

\newpage

#### 2.3.8.2 Distribution of Average Ratings per Variable  

We will now concentrate exclusively on the variables that have a sufficient number of distinct values: userId, movieId, title and year. We can also consider the combination timestamp month-year as it has more than 150 values. Our goal is to determine whether their distributions closely resemble that of the ratings. The figures below illustrate the distribution of ratings for these variables :

```{r, echo=FALSE, fig.align="center", fig.cap = "Distribution of ratings", fig.height=4}
plot_grid(
  ggplot(avg_rating_per_user, aes(x = avg_rating)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "Users"),
  
  ggplot(avg_rating_per_movie, aes(x = avg_rating)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "Movies"),
  
  ggplot(avg_rating_per_genres, aes(x = avg_rating)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "Genres"),
  
  ggplot(avg_rating_per_year, aes(x = avg_rating)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "Year"),

  ggplot(avg_rating_per_t_month_year, aes(x = avg_rating)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "T Month Year"),
  
  ncol = 2, align = 'hv', rel_heights = c(2, 2, 2))
```

We want the prediction to be as close as possible to the rating, so they should have the same shape.

The year plot is not normal and won't be considered for future work.

The other four plots show approximately a normal distribution centered around 3.5 to 4, similar to the rounded ratings. There are a good start to try to predict the ratings.

\newpage

We can enhance our analysis by comparing the average rating for each variable (expressed as a percentage) to the distribution of ratings. The dashed line, representing the count of rounded ratings, is illustrated in Figure 11 :

```{r, echo=FALSE, fig.align="center", fig.cap = "Distribution of ratings", fig.height=4}
plot_grid(
  ggplot() +
    geom_histogram(data = avg_rating_per_user, aes(x = avg_rating, y = after_stat(count) / sum(after_stat(count)) * 100), 
                   color = "darkred", fill = "darkred", alpha = 0.1, position = "dodge", bins = 10) +
    geom_line(data = edx_movies_summarized, aes(x = rating, y = percentage), color = "darkred", size = 1, linetype = "dashed") +
    scale_color_brewer(palette = "Accent") + 
    theme_minimal() + 
    theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "User") +
    scale_y_continuous(labels = percent_format(scale = 1)) +
    scale_x_continuous(breaks = seq(1, 5, 1)),
  
  ggplot() +
    geom_histogram(data = avg_rating_per_movie, aes(x = avg_rating, y = after_stat(count) / sum(after_stat(count)) * 100), 
                   color = "darkred", fill = "darkred", alpha = 0.1, position = "dodge", bins = 10) +
    geom_line(data = edx_movies_summarized, aes(x = rating, y = percentage), color = "darkred", size = 1, linetype = "dashed") +
    scale_color_brewer(palette = "Accent") + 
    theme_minimal() + 
    theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "Movie") +
    scale_y_continuous(labels = percent_format(scale = 1)) +
    scale_x_continuous(breaks = seq(1, 5, 1)),
  
  ggplot() +
    geom_histogram(data = avg_rating_per_genres, aes(x = avg_rating, y = after_stat(count) / sum(after_stat(count)) * 100), 
                   color = "darkred", fill = "darkred", alpha = 0.1, position = "dodge", bins = 10) +
    geom_line(data = edx_movies_summarized, aes(x = rating, y = percentage), color = "darkred", size = 1, linetype = "dashed") +
    scale_color_brewer(palette = "Accent") + 
    theme_minimal() + 
    theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "Genres") +
    scale_y_continuous(labels = percent_format(scale = 1)) +
    scale_x_continuous(breaks = seq(1, 5, 1)),
  
  ggplot() +
    geom_histogram(data = avg_rating_per_t_month_year, aes(x = avg_rating, y = after_stat(count) / sum(after_stat(count)) * 100), 
                   color = "darkred", fill = "darkred", alpha = 0.1, position = "dodge", bins = 10) +
    geom_line(data = edx_movies_summarized, aes(x = rating, y = percentage), color = "darkred", size = 1, linetype = "dashed") +
    scale_color_brewer(palette = "Accent") + 
    theme_minimal() + 
    theme(legend.position = "top", legend.justification = c(0.5, 0), text = element_text(size = 9)) +
    labs(x = "Rating", y = "T Month Year") +
    scale_y_continuous(labels = percent_format(scale = 1)) +
    scale_x_continuous(breaks = seq(1, 5, 1)),
  
  ncol = 2, align = 'hv', rel_heights = c(2, 2, 2))
```
We can see that the movie distribution plot is the closest to the rating one, followed by the user and genres plots. The timestamp month-year isn't close to the rating distribution and won't be considered in future work.

\newpage

#### 2.3.8.3 Distribution of Average Ratings per group of Variables  

As noted in Section 2.3.6, not only did the number of ratings rise significantly over the years (particularly during the 1980s) but this increase also varied by movie genre. For instance, genres like Drama experienced a substantial surge in ratings, while others, such as Documentary, saw a more modest increase. Interestingly, we also observed that the number of ratings per movie could decline, as was the case with the Animation genre.

We will now analyze the use of multiple variables to determine whether the distribution of ratings per interaction resembles the overall distribution of ratings.

We will group these variables together as follows :

\small
```{r eval=FALSE}
avg_rating_per_movieId_year <- edx_movies %>%
  group_by(movieId, year) %>%
  summarise(avg_rating = mean(rating)) %>%
  ungroup()
```
\normalsize

or for 3 variables : 

\small
```{r eval=FALSE}
avg_rating_per_movieId_year_genres <- edx_movies %>%
  group_by(movieId, year, genres) %>%
  summarise(avg_rating = mean(rating)) %>%
  ungroup()
```
\normalsize

We will focus solely on the groups identified in Section 2.3.3, as they are the only ones with repeated values and are likely to appear in the test dataset :

\begin{table}[ht]
\centering
\begin{tabular}{lll}
    (movieId, t\_year) & (userId, t\_year) & (t\_year, genres) \\
    (movieId, year) & (movieId, genres) & (year, genres) \\
    (t\_year, year) & (movieId, t\_year, year) & (movieId, t\_year, genres) \\
    (t\_year, year, genres) & (movieId, year, genres) &  \\
\end{tabular}
\end{table}

\newpage

The following plots show the distribution of ratings per group of variables :

```{r, echo=FALSE, fig.align="center", fig.cap = "Comparison of the Distribution of ratings", fig.height=5}
plot_grid(plotlist = plot_list, ncol = 3)
```

The (movieId, t_year), (movieId, t_year, year) and (movieId, t_year, genres) combinations have approximately the same shape and the closest to the rating one (dashed line).

Then the (movieId, year), (movieId, genres), (movieId, year, genres) and (t_year, genres) combinations show a good approximation of the rating shape.

The (t_year, year, genres), (userId, t_year) and (year, genres) combinations have a good approximation, and the (t_year, year) one doesn't show a good one.

\newpage

# 3 Predictions

The objective of this exercise is to predict ratings and achieve the lowest possible root mean square error (RMSE). RMSE is defined as :

\begin{equation}
\Large
RMSE = \sqrt{\frac{1}{N} \sum_{i} \left( \hat{y}_{i} - y_{i} \right)^{2}}
\end{equation}

where :  
\( y_{i} \) : The observed values (actual ratings).  
\( \hat{y}_{i} \) : The predicted values (model outputs).  
\( N \): The number of observations.  

## 3.1 Target

The target RMSE we aim to achieve (a lower value) is: RMSE = 0.86490.

## 3.2 Linear Regression

The first approach involves using a linear regression model to train on the training dataset (edx_movies) and then applying it to predict ratings on the test dataset. We will compare these predictions against the original ratings to calculate the RMSE.

However, given that the training dataset contains 9 million observations, it may be challenging to train a model efficiently.

The following code demonstrates how to train and test a linear regression model using the edx_movies dataset with the movieId and userId variables :

\small
```{r eval=FALSE}
linear_model <- lm(rating ~ movieId + userId, data = edx_movies)
predictions <- predict(linear_model, newdata = edx_movies)
RMSE(edx_movies$rating, predictions)
```
\normalsize

The returned RMSE is 1.060306

To reduce this error, we can consider including additional variables in the prediction model. However, adding just one more variable leads to a memory error:

\small
```{r eval=FALSE}
linear_model <- lm(rating ~ movieId + userId + genres, data = edx_movies)
# Error: cannot allocate vector of size 53.6 Gb
predictions <- predict(linear_model, newdata = edx_movies)
RMSE(edx_movies$rating, predictions)
```
\normalsize

Other machine learning models, such as random forests, also encounter similar memory errors.

In conclusion, due to the limitations imposed by memory and processing resources, we need to explore alternative methods for calculating our predictions.

## 3.3 Average

The average for the predictions is : $\mu$ = 3.512465

If we choose a constant number for the predictions, then $\mu$ will be the one which will give the minimum RMSE :

\begin{equation}
\Large
\hat{y}_{i} = \mu
\end{equation}

The RMSE will then be : RMSE = 1.060331

The error can be defined as :

\begin{equation}
\Large
\epsilon_{i} = \hat{y}_{i} - y_{i}
\end{equation}

The following plots illustrate the distribution of ratings in descending order, with the average value represented by a horizontal orange line. The plot on the right depicts the distribution of errors :

```{r, echo=FALSE, fig.align="center", fig.cap = "Prediction (average)", fig.height=2}
plot_grid(
  edx_movies %>% select(rating) %>% sample_n(10000) %>% arrange(desc(rating)) %>%
  mutate(index = row_number()) %>%
  ggplot(aes(x = index, y = rating)) +
  geom_area(color = "darkred", fill="darkred", alpha = 0.1) +
  geom_hline(yintercept = mu, color = "orange", linetype = "dashed", size = 1) +
  theme_minimal() + theme(text = element_text(size = 9)) +
  labs(x = "Index", y = "Rating"),
  
  ggplot(edx_movies, aes(x = rating - mu)) +
  geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
  scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
  scale_color_brewer(palette="Accent") + 
  theme_minimal() + theme(text = element_text(size = 9), legend.position = "top") +
  labs(x = "Error", y = "Number of Ratings"),
  
  ncol = 2, align = 'hv', rel_heights = c(2, 2))
```

## 3.4 Bias (simple)

The next step is to introduce a bias so the prediction can be written :
\begin{equation}
\Large
\hat{y}_{i} = \mu + b_{v,i}
\end{equation}

with :
\begin{equation}
\Large
b_{v,i} = \frac{1}{N} \sum_{j} \left( y_{i,j} - \mu \right)
\end{equation}

where :  
\( \hat{y}_{i} \) : The predicted values for a variable v (model outputs).  
\( b_{v,i} \) : The bias for a variable v.  

\newpage

The figure below illustrates our objective. For each movie, we calculate the average rating. In this example, there are three movies, each represented by different colors, with individual points indicating their ratings. The line or segment displays the average rating for each specific movie. The orange line shows the global average :

```{r, echo=FALSE, fig.align="center", fig.cap = "Bias", fig.width=4, fig.height=3}
ggplot(selected_ratings, aes(x = index, y = rating, color = as.factor(movieId))) +
  geom_point(size = 1) +
  labs(x = "Index", y = "Rating") +
  theme_minimal() +
  theme(text = element_text(size = 9), legend.position = "none") +
  geom_segment(data = lines_data, 
               aes(x = x_start, xend = x_end, y = avg_rating, yend = avg_rating, color = as.factor(movieId)),
               linetype = "solid", size = 2) +
  geom_hline(yintercept = mu, color = "orange", linetype = "dashed", size = 1)
```

During the prediction process, we will default to the overall average rating. We will then adjust this by adding the difference between the average rating for each movie and the global average \(\mu\), with this difference representing the bias.

If the same movie appears in the test dataset, we will use its average rating. Otherwise, we will predict the global average from the training dataset. This approach should result in a lower RMSE.

The table below presents the RMSE values for different prediction types used in our analysis : average and bias for Movie, User, and Genres. This choice was due to the comparison of the distribution of average ratings between User, Movie, Genres and Year (timestamp) shown in section 2.3.8.2.

```{r, echo=FALSE}
data_summary <- results %>%
        filter(Type %in% c("Target", "Average", "Movie", "User", "Genres"))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

The table above shows that predictions based on movies produce the best results compared to the other features considered. Therefore, we will concentrate on using the movie variable for future work.

\newpage

The following four plots illustrate the distribution of errors for the biases associated with movies, users and genres. Ideally, we want the errors to be as close to zero as possible. The plots clearly indicate that the genre bias falls short. The movie bias demonstrates the best performance, followed closely by the user bias.

This trend aligns with the RMSE results obtained earlier.

```{r, echo=FALSE, fig.align="center", fig.cap = "Distribution of error (Bias)", fig.height=4}
# Distribution of the error for the bias :
plot_grid(
  ggplot(edx_movies, aes(x = rating - mu - b_m)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(text = element_text(size = 9), legend.position = "top") +
    labs(x = "Error", y = "Movie"),
  
  ggplot(edx_movies, aes(x = rating - mu - b_u)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(text = element_text(size = 9), legend.position = "top") +
    labs(x = "Error", y = "User"),
  
  ggplot(edx_movies, aes(x = rating - mu - b_g)) +
    geom_histogram(color="darkred", fill="darkred", alpha = 0.1, position="dodge", bins = 30) +
    scale_y_continuous(labels = label_number(scale = 1e-6, suffix = "M")) +
    scale_color_brewer(palette="Accent") + 
    theme_minimal() + theme(text = element_text(size = 9), legend.position = "top") +
    labs(x = "Error", y = "Genres"),

  ncol = 2, align = 'hv', rel_heights = c(2, 2, 2))
```

As an example, some predictions for the movie bias are shown in the table below :

```{r, echo=FALSE}
edx_sample <- edx_movies %>%
  mutate(Movie = mu + b_m,
         Movie_User = mu + b_m + b_mu,
         Interaction = mu + b_v + b_w + b_x,
         diff_1 = abs(rating - mu - b_v),
         diff_2 = abs(rating - mu - b_v - b_w),
         diff_3 = abs(rating - mu - b_v - b_w - b_x)
  ) %>%
  filter(nchar(title) <= 30,
         diff_3 <= diff_2,
         diff_2 <= diff_1) %>%
  select(userId, movieId, title, year, rating, Movie, Movie_User, Interaction) %>%
  sample_n(5)
data_summary <- edx_sample %>% select(userId, movieId, title, year, rating, Movie)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

## 3.5 Bias (Multiple)

The next step is to introduce a second bias so the prediction can be written :
\begin{equation}
\Large
\hat{y}_{v,w,i} = \mu + b_{v,i} + b_{w,i}
\end{equation}

where :  
\( \hat{y}_{v,i} \) : The predicted values for a variable v (model outputs).  
\( b_{v,i} \) : The bias for a variable v.  
\( b_{w,i} \) : The bias for a variable w.  

We can keep the same formula (5) for the 2 biases, which will give a better RMSE for the movie and user variables : **0.8767534**

However, we can even fine tune the calculation of the bias. If we keep the same formula as (5) for the first bias, we can calculate the next one with this formulas :

\begin{equation}
\Large
b_{w,i} = \frac{1}{N} \sum_{j} \left( y_{i,j} - \mu - b_{v,j} \right)
\end{equation}

The first bias is defined as the difference between the overall average and the average for a specific movie (or user or genre).

The definition of the second bias has changed. When the first bias pertains to the movie, the second bias—applicable to the user—will be the difference between the average rating for a specific user and the average of the predicted ratings for the movies that this user has rated.

The table below presents the RMSE values for different prediction types used in our analysis : average and bias for Movie, and the multiple biases applied to Movie and User, and Movie, User and Genres.

```{r, echo=FALSE}
data_summary <- results %>%
        filter(Type %in% c("Target", "Average", "Movie", "Movie + User", "Movie + User + Genres"))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))

```

\newpage

The following plot show the distribution of errors for the Movie bias (simple) and the Movie + User one (multiple) :

```{r, echo=FALSE, fig.align="center", fig.cap = "Comparison of the Distribution of errors", fig.width=4, fig.height=3}
bind_rows(
  edx_movies %>% mutate(err = rating - mu - b_m, Type = "Movie") %>% select(rating, err, Type),
  edx_movies %>% mutate(err = rating - mu - b_m - b_mu, Type = "Movie+User") %>% select(rating, err, Type)
) %>%
  group_by(Type) %>%
  do(data.frame(density = density(.$err)$y, err = density(.$err)$x)) %>%
  ggplot(aes(x = err, y = density, color = Type)) +
  geom_line(size = 1) +  # Use geom_line for lines instead of areas
  scale_color_manual(values = c("Movie" = "darkred", "Movie+User" = "grey")) +
  labs(x = "Error", y = "Density") +
  theme_minimal() + theme(text = element_text(size = 9), legend.position = "top")
```

As an example, some predictions for the movie and user biases are shown in the table below :

```{r, echo=FALSE}
data_summary <- edx_sample %>% select(userId, movieId, title, year, rating, Movie, Movie_User)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

## 3.6 Regularisation

Regularization adjusts the model's bias by incorporating penalty terms into the loss function. This adjustment helps to tune the model's complexity, making it more robust against overfitting. By adding penalties to large coefficients, regularization reduces the influence of outliers. This results in a model that doesn’t react excessively to extreme values in the data.

The bias formulas for the movies and the users can now be written :

\begin{equation}
\Large
b_{m} = \frac{\displaystyle\sum_{j} (y_{j} - \mu)}{N + \lambda}
\end{equation}

and :

\begin{equation}
\Large
b_{u,m} = \frac{\displaystyle\sum_{j} (y_{j} - \mu - b_{m})}{N + \lambda}
\end{equation}

The figure below shows how the (RMSE varies with the regularisation parameter $\lambda$ :  
  
```{r, echo=FALSE, fig.align="center", fig.cap = "Cross‑validated RMSE vs Regularisation Strength", fig.width=4, fig.height=3}
ggplot(mapping = aes(x = lambdas, y = rmse_arr)) +
  geom_point(color = "darkred") +
  labs(x = "Lambda", y = "RMSE") +
  theme_minimal() + theme(text = element_text(size = 9), legend.position = "top")
```

The minimum value is reached when $\lambda$ = 0.5, the RMSE is then **0.8566952**.

This result is a litle bit below the Movie + User method :

```{r, echo=FALSE}
data_summary <- results %>%
        filter(Type %in% c("Target", "Average", "Movie", "Movie + User", "Regularisation (Movie + User)"))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

\newpage

## 3.7 Interaction

As we discussed earlier in section 2.3.8.3, we can estimate ratings using one or more variables.

Now, we will compare the RMSE values obtained by replacing the biases for Movies, Users, and Genres with different combinations :  

movieId   ->    (movieId, t_year)   
userId    ->    (userId, t_year)  
genres    ->    (movieId, t_year, genres)  

The rationale for these combinations is as follows :  

 - The pair (movieId, t_year) showed the best distribution shape in section 2.3.8.3.  
 - The combination (userId, t_year) was the only one incorporating userId that had a reasonably good distribution.  
 - The group (movieId, t_year, genres) provided the best distribution of ratings that included the genres variable.  

The following R code performs bias calculation on (movieId, t_year) based on the edx_movies dataset and joins the results back into the dataset :

```{r eval=FALSE}
# Calculate bias for each movie and year, and join to the edx_movies dataset
b_v <- edx_movies %>%
  group_by(movieId, t_year) %>%
  summarise(b_v = mean(rating - mu))

edx_movies <- edx_movies %>%
  left_join(b_v, by = c("movieId", "t_year")) %>%
  mutate(b_v = replace_na(b_v, 0))
```

The table below illustrate the comparison of RMSEs between the Movie, User and Genres variables, and the groups variables :

```{r, echo=FALSE}
# Define the desired order for the filter
desired_order <- c("Target", "Average", "Movie", "movieId, t_year", 
                   "User", "userId, t_year", "Genres", "movieId, t_year, genres")
# Filter and order the results
data_summary <- results %>%
  filter(Type %in% desired_order) %>%
  mutate(Type = factor(Type, levels = desired_order)) %>%
  arrange(Type)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position")) %>%
  row_spec(c(seq(3, 4), seq(7, 8)), background = "#f2f2f2")
```

In each case, we achieve a lower RMSE by utilizing a combination of variables rather than relying on a single variable.

As we saw before, we had the lowest RMSE by applying a bias on the movie variable before the user and the genres ones, so we will continue with the groups (movieId, t_year), (userId, t_year) and then (movieId, t_year, genres).

To further reduce the RMSE, we will also apply a regularization with the same value of $\lambda$ as found earlier (0.5).

\newpage

The formulas for the 3 bias will then be :

\begin{equation}
\Large
b_{v} = \frac{\displaystyle\sum_{j} (y_{j} - \mu)}{N + \lambda}
\end{equation}

\begin{equation}
\Large
b_{w} = \frac{\displaystyle\sum_{j} (y_{j} - \mu - b_{v})}{N + \lambda}
\end{equation}

\begin{equation}
\Large
b_{x} = \frac{\displaystyle\sum_{j} (y_{j} - \mu - b_{v} - b_{w})}{N + \lambda}
\end{equation}

The following R code performs bias calculations based on the edx_movies dataset and joins the results back into the dataset:

```{r eval=FALSE}
# Calculate bias for movieId and t_year
b_v <- edx_movies %>%
  group_by(movieId, t_year) %>%
  summarise(b_v = sum(rating - mu)/(n() + lambda))

# Join to the edx_movies dataset
edx_movies <- edx_movies %>%
  left_join(b_v, by = c("movieId", "t_year")) %>%
  mutate(b_v = replace_na(b_v, 0))

# Calculate bias for userId and t_year
b_w <- edx_movies %>%
  group_by(userId, t_year) %>%
  summarise(b_w = sum(rating - mu - b_v)/(n() + lambda))

# Join to the edx_movies dataset
edx_movies <- edx_movies %>%
  left_join(b_w, by = c("userId", "t_year")) %>%
  mutate(b_w = replace_na(b_w, 0))

# Calculate bias for movieId, t_year and genres
b_x <- edx_movies %>%
  group_by(movieId, t_year, genres) %>%
  summarise(b_x = sum(rating - mu - b_v - b_w)/(n() + lambda))

# Join to the edx_movies dataset
edx_movies <- edx_movies %>%
  left_join(b_x, by = c("movieId", "t_year", "genres")) %>%
  mutate(b_x = replace_na(b_x, 0))
```

\newpage

After incorporating the three bias components, the model achieves an RMSE of **0.8417134** on the train set.

```{r, echo=FALSE}
# Define the desired order for the filter
desired_order <- c("Target", "Average", "Movie",
                   "Regularisation (Movie + User)", 
                   "Interaction")
# Filter and order the results
data_summary <- results %>%
  filter(Type %in% desired_order) %>%
  mutate(Type = factor(Type, levels = desired_order)) %>%
  arrange(Type)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

As an example, some predictions are shown in the table below :

```{r, echo=FALSE}
data_summary <- edx_sample %>% select(userId, movieId, title, year, rating, Movie, Movie_User, Interaction)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

## 3.8 Clamping

While we have now a relatively low RMSE of 0.8417290, further analysis of the data shows that the predicted values range from -1 to 6.2 when the ratings range from 0.5 to 5 :

```{r, echo=FALSE}
data_summary <- data.frame(Variable = c("Rating", "Prediction"),
                           Min = c(min(edx_movies$rating), min(edx_movies$pred)),
                           Max = c(max(edx_movies$rating), max(edx_movies$pred)))
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

We should be able to reduce the RMSE by replacing all values out of the expected range by 0.5 or 5. We can even go further by replacing all values outside a smaller range by 0.5 or 5.

Let's try first with the maximum value a prediction can take. The graph below shows that the minimum RMSE we can get is when we clamp all data above 4.64 ($r_{max}$) :

```{r, echo=FALSE, fig.align="center", fig.cap = "RMSE vs RMax", fig.width=4, fig.height=2}
ggplot(mapping = aes(x = rmaxs, y = rmse_clamp_max_arr)) +
  geom_point(color = "darkred") +
  labs(x = "RMax", y = "RMSE") +
  theme_minimal() + theme(text = element_text(size = 9), legend.position = "top")
```

\newpage

Using a maximum value of 4.64, we can continue and determine the minimum value which will give us the best RMSE is $r_{min}$ = 0.93 :

```{r, echo=FALSE, fig.align="center", fig.cap = "RMSE vs RMin", fig.width=4, fig.height=2}
ggplot(mapping = aes(x = rmins, y = rmse_clamp_min_arr)) +
  geom_point(color = "darkred") +
  labs(x = "RMin", y = "RMSE") +
  theme_minimal() + theme(text = element_text(size = 9), legend.position = "top")
```

We now have an RMSE of **0.8412219** :

```{r, echo=FALSE}
# Define the desired order for the filter
desired_order <- c("Target", "Average", "Movie",
                   "Regularisation (Movie + User)", 
                   "Interaction",
                   "Interaction + Clamping")
# Filter and order the results
data_summary <- results %>%
  filter(Type %in% desired_order) %>%
  mutate(Type = factor(Type, levels = desired_order)) %>%
  arrange(Type)
kable(data_summary, format = "latex", booktabs = TRUE, linesep = "", format.args = list(big.mark = ",")) %>%
  kable_styling(font_size = 9, latex_options = c("hold_position"))
```

\newpage

# 4 Final Test

We now apply the latest prediction algorithm to the final_holdout_test data set.

We first need to extract the timestamp year and the release year :

```{r eval=FALSE}
final_holdout_test_movies <- final_holdout_test %>%
  mutate(
    datetime = as.POSIXct(timestamp, origin = "1970-01-01", tz = "UTC"),
    t_year = year(datetime),
    year = as.integer(str_extract(title, "(?<=\\()\\d{4}(?=\\))"))
  ) %>%
  select(userId, movieId, rating, t_year, title, year, genres)
```

Then join the bias terms b_v, b_w and b_x calculated in section 3.7 :

```{r eval=FALSE}
final_holdout_test_movies <- final_holdout_test_movies %>%
  left_join(b_v, by = c("movieId", "t_year")) %>%
  mutate(b_v = replace_na(b_v, 0))

final_holdout_test_movies <- final_holdout_test_movies %>%
  left_join(b_w, by = c("userId", "t_year")) %>%
  mutate(b_w = replace_na(b_w, 0))

final_holdout_test_movies <- final_holdout_test_movies %>%
  left_join(b_x, by = c("movieId", "t_year", "genres")) %>%
  mutate(b_x = replace_na(b_x, 0))
```

And compute the predictions :

The predicted rating is the global mean ($\mu$) plus the three bias components.
The result is then clamped to the admissible rating range $r_{min}$, $r_{max}$ where $r_{min}$ and $r_{max}$ were determined in section 3.8.

```{r eval=FALSE}
final_holdout_test_movies$pred <- pmin(pmax(mu +
                                              final_holdout_test_movies$b_v +
                                              final_holdout_test_movies$b_w +
                                              final_holdout_test_movies$b_x, rmin), rmax)
```

Evaluate the model :

The Root Mean Squared Error (RMSE) is computed by comparing the observed ratings with the predicted values.

```{r eval=FALSE}
RMSE(final_holdout_test_movies$rating, final_holdout_test_movies$pred)
```

The final RMSE obtained on the hold‑out test set is **\large0.8579874**.

\newpage

# 5 Conclusion

We achieved our target with an RMSE of 0.8579874, which is below the required maximum of 0.86490.
However, this value is relatively high within the context of a rating scale from 0 to 5, suggesting that there is potential for further improvements.

The average rating in the dataset is 3.51, which surpasses the midpoint of 2.5 in a range where ratings extend from 0.5 to 5.
This indicates that users generally assigned favorable scores to the movies they watched, implying that they primarily selected films they anticipated enjoying.

The data analysis indicated that ratings are primarily influenced by movieId, followed by userId, genres, year, and surprisingly, timestamp year. Notably, this analysis was done on a work laptop with limited computing resources (primarily intended for Office applications) but still managed to attain a relatively low RMSE.

To achieve these results, we experimented with various bias-based methods and selected the combination that excelled on the validation data.

There are opportunities for further improvements. The distribution of ratings in the training set isn't perfectly normal, primarily due to a subset of users consistently providing half-star ratings. By separating the data into half-mark and full-mark subsets, we could better approximate a normal distribution for each.

A promising next step involves a two-stage modeling approach:

Stage 1 – Classification: Predict whether a user will assign a half-mark or a full mark to a given movie. This binary decision could be modeled using logistic regression, a tree-based classifier, or other suitable machine learning algorithms.

Stage 2 – Regression: Apply distinct bias-adjusted regression formulas for both groups. Each regression would utilize the appropriate bias terms (movie, user, time, etc.) tailored to that specific subgroup.

By first determining the likely rating granularity and then employing specialized regression models, we expect to further reduce prediction error.

Additionally, we plan to optimize the code to enhance execution speed and minimize runtime. Furthermore, we aim to explore the applicability of linear regression or alternative algorithms like k-nearest neighbors (k-NN) and random forest, while also investigating the integration of Matrix Factorization techniques. Through these enhancements to our modeling strategy, we anticipate significant reductions in prediction error and improved overall efficiency in our analysis.